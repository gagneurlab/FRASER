@article{Benjamini2001,
abstract = {Benjamini and Hochberg suggest that the false discovery rate may be the appropriate error rate to control in many applied multiple testing prob-lems. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. This condition for positive dependency is general enough to cover many problems of prac-tical interest, including the comparisons of many treatments with a single control, multivariate normal test statistics with positive correlation matrix and multivariate t. Furthermore, the test statistics may be discrete, and the tested hypotheses composite without posing special difficulties. For all other forms of dependency, a simple conservative modification of the proce-dure controls the false discovery rate. Thus the range of problems for which a procedure with proven FDR control can be offered is greatly increased.},
archivePrefix = {arXiv},
arxivId = {0801.1095},
author = {Benjamini, Yoav and Yekutieli, Daniel},
doi = {10.1214/aos/1013699998},
eprint = {0801.1095},
file = {::},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Discrete test statistics,FDR,Hochberg's procedure,MTP2 densities,Multiple comparisons procedures,Multiple endpoints many-to-one comparisons,Positive regression dependency,Simes' equality,Unidimensional latent variables},
number = {4},
pages = {1165--1188},
pmid = {18298808},
title = {{The control of the false discovery rate in multiple testing under dependency}},
url = {https://projecteuclid.org/euclid.aos/1013699998},
volume = {29},
year = {2001}
}
@article{Pervouchine2012,
  doi = {10.1093/bioinformatics/bts678},
  url = {https://doi.org/10.1093/bioinformatics/bts678},
  year = {2012},
  month = nov,
  publisher = {Oxford University Press ({OUP})},
  volume = {29},
  number = {2},
  pages = {273--274},
  author = {D. D. Pervouchine and D. G. Knowles and R. Guigo},
  title = {Intron-centric estimation of alternative splicing from {RNA}-seq data},
  journal = {Bioinformatics}
}
@article{Dobin2013,
  doi = {10.1093/bioinformatics/bts635},
  url = {https://doi.org/10.1093/bioinformatics/bts635},
  year = {2013},
  month = jan,
  publisher = {Oxford University Press ({OUP})},
  volume = {29},
  number = {1},
  pages = {15--21},
  author = {Alexander Dobin and Carrie A. Davis and Felix Schlesinger and Jorg Drenkow and Chris Zaleski and Sonali Jha and Philippe Batut and Mark Chaisson and Thomas R. Gingeras},
  title = {{STAR}: ultrafast universal {RNA}-seq aligner},
  journal = {Bioinformatics}
}
@article{MarcoSola2012,
  doi = {10.1038/nmeth.2221},
  url = {https://doi.org/10.1038/nmeth.2221},
  year = {2012},
  month = oct,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {9},
  number = {12},
  pages = {1185--1188},
  author = {Santiago Marco-Sola and Michael Sammeth and Roderic Guig{\'{o}} and Paolo Ribeca},
  title = {The {GEM} mapper: fast,  accurate and versatile alignment by filtration},
  journal = {Nature Methods}
}
@article{Gavish2013,
 abstract = {We consider recovery of low-rank matrices from noisy data by hard thresholding of singular values, where singular values below a prescribed threshold {\$}\lambda{\$} are set to 0. We study the asymptotic MSE in a framework where the matrix size is large compared to the rank of the matrix to be recovered, and the signal-to-noise ratio of the low-rank piece stays constant. The AMSE-optimal choice of hard threshold, in the case of n-by-n matrix in noise level $\backslash$sigma, is simply {\$}(4/\sqrt{3}) \sqrt{n}$\backslash$sigma $\backslash$approx 2.309 \sqrt{n}$\backslash$sigma{\$} when {\$}$\backslash$sigma{\$} is known, or simply {\$}2.858$\backslash$cdot y{\_}{med}{\$} when {\$}$\backslash$sigma{\$} is unknown, where {\$}y{\_}{med}{\$} is the median empirical singular value. For nonsquare $m$ by $n$ matrices with {\$}m $\backslash$neq n{\$}, these thresholding coefficients are replaced with different provided constants. In our asymptotic framework, this thresholding rule adapts to unknown rank and to unknown noise level in an optimal manner: it is always better than hard thresholding at any other value, no matter what the matrix is that we are trying to recover, and is always better than ideal Truncated SVD (TSVD), which truncates at the true rank of the low-rank matrix we are trying to recover. Hard thresholding at the recommended value to recover an n-by-n matrix of rank r guarantees an AMSE at most {\$}3nr$\backslash$sigma{\^{}}2{\$}. In comparison, the guarantee provided by TSVD is {\$}5nr$\backslash$sigma{\^{}}2{\$}, the guarantee provided by optimally tuned singular value soft thresholding is {\$}6nr$\backslash$sigma{\^{}}2{\$}, and the best guarantee achievable by any shrinkage of the data singular values is {\$}2nr$\backslash$sigma{\^{}}2{\$}. Empirical evidence shows that these AMSE properties of the {\$}4/\sqrt{3}{\$} thresholding rule remain valid even for relatively small n, and that performance improvement over TSVD and other shrinkage rules is substantial, turning it into the practical hard threshold of choice.},
 author = {Gavish, Matan and Donoho, David L.},
 date = {25.05.2013},
 title = {{The Optimal Hard Threshold for Singular Values is 4/sqrt(3)}},
 url = {http://arxiv.org/pdf/1305.5870},
 file = {Gavish, Donoho 25.05.2013 - The Optimal Hard Threshold:Attachments/Gavish, Donoho 25.05.2013 - The Optimal Hard Threshold.pdf:application/pdf}
}